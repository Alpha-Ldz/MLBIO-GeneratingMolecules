{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbC4SbdYnQ_H"
      },
      "source": [
        "# RNN Based molucule generation \n",
        "\n",
        "Laurent Cetinsoy\n",
        "\n",
        "In this hands-on we want to generate molecule formulas for denovo-drug discovery. \n",
        "\n",
        "For that we need to use Generative models. Generative models are models which goes beyond classification or simple regression : they are able to generate data that look like previously seens dataset. \n",
        "\n",
        "There exists a lot of models : \n",
        "\n",
        "- Bayesian models like graphical models\n",
        "- Recurrent models (for sequence generation like texte)\n",
        "- Variational auto encoders\n",
        "- Generative adversarial models\n",
        "- Flow and diffusion models \n",
        "\n",
        "\n",
        "In the hands-on we will start by  trainning a character based RNN to generate smile molecules\n",
        "\n",
        "\n",
        "We want to feed smile representations of molecules to an RNN.\n",
        "The basic idea is we will train it to predict the next smile token of a molecule given the previous one. \n",
        "\n",
        "For instance for the following molecule \"CC(=O)NC1=CC=C(O)C=C1\" will may give to the model\n",
        "\n",
        "X = \"CC(=O)N\" \n",
        "y = C\n",
        "\n",
        "and ask the RNN to learn to predict y given X\n",
        "\n",
        "Like a standard language model !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9a_6LxKnQ_K"
      },
      "source": [
        "## RNN Language model \n",
        "\n",
        "\n",
        "A language model is a model which predict the next token of a sequence given the previous ones : \n",
        "\n",
        "$ P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n",
        "\n",
        "\n",
        "This model can be learned with a Recurrent neural network \n",
        "\n",
        "$ y = P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p}) = RNN_{\\theta} (X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n",
        "\n",
        "\n",
        "In order to train such model you need a corpus of data. \n",
        "\n",
        "\n",
        "\n",
        "There are two main ways to do that : Word level model or character level model\n",
        "\n",
        "For character level models, an interesting resource is : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n16RRsp0nQ_K"
      },
      "source": [
        "Explain briefly what is the difference between word based language model and character based language model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6BKMv85nQ_K"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-43vJAynQ_L"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNVQsuanQ_L"
      },
      "source": [
        "Dowload the following dataset : https://github.com/joeymach/Leveraging-VAE-to-generate-molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGl1-gWcnQ_L",
        "outputId": "60ad1896-03df-41b6-e6af-278eb0bd0f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path './data' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/joeymach/Leveraging-VAE-to-generate-molecules.git ./data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cle0GvjCnQ_N"
      },
      "source": [
        "Import pandas and load the first 1000 lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ieBilA6-nQ_N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import the first 1000 lines\n",
        "df = pd.read_csv('./data/250k_smiles.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4H3IZ5FnQ_O"
      },
      "source": [
        "Display the first rows of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "0yiYvy97nQ_O",
        "outputId": "44604c1d-7354-4291-8846-fc30d4142a33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      smiles    logP       qed       SAS\n",
              "0  CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n  5.0506  0.702012  2.084095"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2276988-f938-46ad-93b3-913dbef23137\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>logP</th>\n",
              "      <th>qed</th>\n",
              "      <th>SAS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n</td>\n",
              "      <td>5.0506</td>\n",
              "      <td>0.702012</td>\n",
              "      <td>2.084095</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2276988-f938-46ad-93b3-913dbef23137')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2276988-f938-46ad-93b3-913dbef23137 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2276988-f938-46ad-93b3-913dbef23137');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGmxeU_ynQ_P"
      },
      "source": [
        "## Processing the data\n",
        "\n",
        "We need to do the following things : \n",
        "\n",
        "- convert smile tokens to numbers\n",
        "- build  smile token sequences and corresponding labels pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j3eBB7cnQ_P"
      },
      "source": [
        "Compute the biggest smile molecule size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeVIR-GXnQ_Q",
        "outputId": "6dcbb42e-6a08-4d7b-ad72-f65686b71990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df['smiles'].str.len().max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuyjHu_SnQ_Q"
      },
      "source": [
        "\n",
        "Code a function **unic_characters(string)** which return the unic characters in a string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0nR_0clMnQ_Q"
      },
      "outputs": [],
      "source": [
        "def unic_characters(string):\n",
        "    rtn = set()\n",
        "    \n",
        "    for char in string:\n",
        "        rtn.add(char)\n",
        "        \n",
        "    return rtn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XSIgZRPnQ_Q"
      },
      "source": [
        "Concatenate all smile string of the pandas dataframe and use **unic_characters** to get the unic_characters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKkil_PlnQ_R",
        "outputId": "6106d5c3-926d-4c2a-bc8c-5aa1f2325889"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "unic_chars = unic_characters(\" \".join(df['smiles']))\n",
        "nb_chars = len(unic_chars) + 1\n",
        "len(unic_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knMaPXTgnQ_R"
      },
      "source": [
        "Code a function **map_char_to_int(unic_chars)** which returns a dictionnary where each char is assigned an int value. \n",
        "Add a character to specify the end of the molecule (like \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xoo_TBManQ_R"
      },
      "outputs": [],
      "source": [
        "ending_tocken = \"\\n\"\n",
        "\n",
        "def map_char_to_int(unic_chars):\n",
        "    rtn = dict()\n",
        "    \n",
        "    for i, char in enumerate(unic_chars):\n",
        "        rtn[char] = i\n",
        "        \n",
        "    rtn[ending_tocken] = len(unic_chars)\n",
        "    return rtn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMBx9z2AnQ_R"
      },
      "source": [
        "Code a function map_int_to_char(unic_chars) which returns the reverse mapping. \n",
        "\n",
        "If you want you can merge both functions in a class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6gGmnfdWnQ_S"
      },
      "outputs": [],
      "source": [
        "def map_int_to_char(unic_chars):\n",
        "    rtn = dict()\n",
        "    \n",
        "    for i, char in enumerate(unic_chars):\n",
        "        rtn[i] = char\n",
        "        len(unic_chars)\n",
        "        \n",
        "    rtn[len(unic_chars)] = ending_tocken\n",
        "    return rtn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzD38556nQ_S"
      },
      "source": [
        "For each smile molecule add the ending token to it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9BP-5-I5nQ_S"
      },
      "outputs": [],
      "source": [
        "df[\"smiles\"] = df[\"smiles\"].apply(lambda x: x + ending_tocken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YkWVeZAenQ_S"
      },
      "outputs": [],
      "source": [
        "dict_char_to_int = map_char_to_int(unic_chars)\n",
        "dict_int_to_char = map_int_to_char(unic_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhkHENEtnQ_S"
      },
      "source": [
        "## Building the dataset\n",
        "\n",
        "Now we will create the dataset so that it has the good share for our Keras LSTM model\n",
        "\n",
        "Remember Keras recurrent models expect a 3D array with shapes (n_examples, seq_len, n_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_7VxxV1nQ_T"
      },
      "source": [
        "What will be n_features in our case ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t54qLwxInQ_T"
      },
      "source": [
        "Ca sera 3 car on a 3 autres colonnes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWNx5YwLnQ_T"
      },
      "source": [
        "Code a function **build_X_and_y(string, i_char, seq_lenght)** which takes a string, a **seq_length** number and a position. \n",
        "\n",
        "\n",
        "It should create X by by getting all character between i and i + seq_length \n",
        "and create y by getting the character following the X sequence\n",
        "it returns X and y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD1SCxk1nQ_T"
      },
      "source": [
        "Test your function on the following string \"\" with seq_length = 4 and i = [1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_NgoWOSnQ_T",
        "outputId": "1897f462-7feb-4131-bdb1-26fb2621051b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('zert', 'y')\n",
            "('erty', 'u')\n",
            "('rtyu', 'i')\n"
          ]
        }
      ],
      "source": [
        "(n_examples, seq_length, n_features) = (len(df),5,1)\n",
        "\n",
        "def build_X_and_y(string, i_char, seq_length):\n",
        "    if(i_char >= len(string) or i_char + seq_length >= len(string)):\n",
        "        return \"\", \"\"\n",
        "    \n",
        "    X = string[i_char:i_char + seq_length]\n",
        "    y = string[i_char + seq_length]\n",
        "    return X, y\n",
        "\n",
        "for i in range(1, 4):\n",
        "    print(build_X_and_y(\"azertyuiop\", i, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CencgK8xnQ_U",
        "outputId": "67ac4b7e-bb75-4b2b-d2cd-06af60945b17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('azert', 'y')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "build_X_and_y(\"azertyuiop\", 0, seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD0uM7OmnQ_U"
      },
      "source": [
        "By using build_X_and_y and map_char_to_int build a list nameed X_train and a list named y_train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1f5pVRlnQ_U",
        "outputId": "60e4a778-a9e2-423c-acc1-4bd55a3b06da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13, 13, 34, 13, 33]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in df['smiles'].tolist():\n",
        "    \n",
        "    X, y = build_X_and_y(i, 0, seq_length)\n",
        "    \n",
        "    X_ = []\n",
        "\n",
        "    y_ = [0] * nb_chars\n",
        "    y_[dict_char_to_int[y]] = 1\n",
        "    \n",
        "    for e in X:\n",
        "        X_.append(dict_char_to_int[e])\n",
        "    \n",
        "    X_train.append(X_)\n",
        "    y_train.append(y_)\n",
        "    \n",
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDdf2nkbnQ_V"
      },
      "source": [
        "Create numpy arrays from the lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb1hKCt8nQ_V",
        "outputId": "878aa628-41ee-4368-a160-d040a79d8aab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249455, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import numpy as np\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmrwCWxEnQ_V"
      },
      "source": [
        "Reshape the X numpy array (n_examples, seq_lenght, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oz2Zixd_nQ_V"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(n_examples, seq_length, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5yV-WQknQ_V"
      },
      "source": [
        "Normalize X by dividing each values by the total number of unic characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xEBNgbzpnQ_V"
      },
      "outputs": [],
      "source": [
        "X_train = X_train /len(unic_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGHesFAfnQ_W"
      },
      "source": [
        "Import Keras and build (at least) a two layered LSTM network with 128 neurone in each.\n",
        "\n",
        "You can also add Dropoutlayers\n",
        "\n",
        "Do you think you should use the return_sequences = True ? If yes, when ? \n",
        "\n",
        "\n",
        "Add a Dense layer on top with with the appropriate activation function and number of neurones \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QQ6xU27BnQ_W"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  lstm_neurons = 128\n",
        "\n",
        "  dropout_rate = 0.2\n",
        "\n",
        "  dense_neurons = 36\n",
        "\n",
        "  dense_activation = 'softmax'\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(LSTM(lstm_neurons, input_shape=(seq_length, 1), return_sequences=True))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(LSTM(lstm_neurons))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  # Add the Dense layer\n",
        "  model.add(Dense(nb_chars, activation=dense_activation))\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i903dkAnQ_W"
      },
      "source": [
        "Compile the model with the appropriate loss function and the adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5jnJPIrcnQ_W"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "def train_model(model):\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "\n",
        "  optimizer = Adam()\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "train_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVKeEORsnQ_X"
      },
      "source": [
        "Train the model on 20 epochs and 10 examples (yeah you read correctly) and check that the model overfits ! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWOlgruDnQ_X",
        "outputId": "28374e27-1bf6-4baf-a972-e3eb7c44b149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 4s 10ms/step - loss: 3.5889 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4930 - accuracy: 0.3000\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.2331 - accuracy: 0.3000\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3400 - accuracy: 0.3000\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0538 - accuracy: 0.3000\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9503 - accuracy: 0.3000\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8358 - accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7316 - accuracy: 0.3000\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8027 - accuracy: 0.3000\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9841 - accuracy: 0.2000\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7489 - accuracy: 0.3000\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7723 - accuracy: 0.3000\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5995 - accuracy: 0.4000\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5776 - accuracy: 0.2000\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8701 - accuracy: 0.3000\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7568 - accuracy: 0.2000\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7601 - accuracy: 0.2000\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7831 - accuracy: 0.3000\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6870 - accuracy: 0.3000\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7836 - accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69941b5e80>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.fit(X_train[:10], y_train[:10], epochs=20, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2swekY51nQ_X"
      },
      "source": [
        "If it does not overfit try to fix data prep and model architecture so it does"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDpgJNednQ_X"
      },
      "source": [
        "It overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JZ0YeH3nQ_X"
      },
      "source": [
        "Create a function **make_prediction(seed_start)** which takes a starting string sequence and uses it to generate a molecule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wOMPy2fYnQ_Y"
      },
      "outputs": [],
      "source": [
        "# Create a function make_prediction(seed_start) wich takes a starting sequence and uses it to generate a molecule\n",
        "\n",
        "def make_prediction(seed_start):\n",
        "    seed = [dict_char_to_int[i] for i in seed_start]\n",
        "    seed = np.array(seed)\n",
        "    seed = seed[-seq_length:]\n",
        "    seed = seed.reshape(1, seq_length, 1)\n",
        "    seed = seed / len(unic_chars)\n",
        "    \n",
        "    prediction = model.predict(seed)\n",
        "    \n",
        "    prediction = np.argmax(prediction)\n",
        "    \n",
        "    return dict_int_to_char[prediction]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXPy-rADnQ_Y"
      },
      "source": [
        "generate a molecule of your overfitted model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u7VwAKznQ_Y",
        "outputId": "4e00da0e-23af-40ef-8d8f-429164288c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "c\n"
          ]
        }
      ],
      "source": [
        "# Test it with a random seed\n",
        "print(make_prediction(\"c1ccc2occ\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SBG9JgGnQ_Y"
      },
      "source": [
        "Make a model checkpoint so that the model is saved after each epoch\n",
        "if you train on a plateform and it stops you do not lose your training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "64fND3LsnQ_Y",
        "outputId": "c15527c3-8891-48e7-d3c6-8a3a11960a13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from keras.callbacks import ModelCheckpoint\\n\\ncheckpoint_filepath = './checkpoint'\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_filepath,\\n    save_weights_only=True,\\n    monitor='val_accuracy',\\n    mode='max',\\n    save_best_only=True)\\n\\nmodel.load_weights(checkpoint_filepath)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\"\"\"from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_filepath = './checkpoint'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.load_weights(checkpoint_filepath)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJiLy9fhnQ_Y"
      },
      "source": [
        "Now go to your favorite plateform (colab or something else) and train the dataset on the whole data for 10 epochs and batch size 256 \n",
        "\n",
        "it should take a long time so either follow the class or go take a nap "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aurc7UanQ_Z",
        "outputId": "a10de9d4-b1ca-4e3c-9474-57cbdfe80107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "975/975 [==============================] - 11s 6ms/step - loss: 1.6345 - accuracy: 0.4935\n",
            "Epoch 2/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.9647 - accuracy: 0.6618\n",
            "Epoch 3/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.8684 - accuracy: 0.6860\n",
            "Epoch 4/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.8236 - accuracy: 0.6960\n",
            "Epoch 5/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.7976 - accuracy: 0.7031\n",
            "Epoch 6/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.7793 - accuracy: 0.7081\n",
            "Epoch 7/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.7653 - accuracy: 0.7105\n",
            "Epoch 8/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.7556 - accuracy: 0.7130\n",
            "Epoch 9/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.7471 - accuracy: 0.7152\n",
            "Epoch 10/10\n",
            "975/975 [==============================] - 6s 6ms/step - loss: 0.7392 - accuracy: 0.7169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f698ee17730>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = create_model()\n",
        "train_model(model)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvFmeKkTnQ_Z"
      },
      "source": [
        "Generate between 100 and 1000 molecules. \n",
        "\n",
        "create a list where molecules have between 10 and 50 atoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "k4nHn4rLnQ_Z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "number = random.randrange(100, 1000)\n",
        "\n",
        "tmp = df[df.smiles.str.len() < 50]\n",
        "tmp = tmp[tmp.smiles.str.len() >= 10]\n",
        "\n",
        "tmp = tmp.sample(n=number)\n",
        "lst = tmp[\"smiles\"].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EewLUTannQ_Z"
      },
      "source": [
        "With rdkit compute the Quantified Estimated Drug likelyness (QED) of each molecule in this subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYwdELd4vJHM",
        "outputId": "266e49e7-defd-42eb-8b9d-30543d6db98e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8FvG_i8nQ_Z",
        "outputId": "a2bf9e02-3398-4011-9e55-7fefc9d87f9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8214218920140605\n",
            "0.7498981151339819\n",
            "0.8279139144574026\n",
            "0.8449665448279098\n",
            "0.7458123362908268\n",
            "0.8438347215153985\n",
            "0.6437888286148052\n",
            "0.8999260183068416\n",
            "0.5974721331066543\n",
            "0.7427322331808208\n",
            "0.833225296393198\n",
            "0.8476209888400327\n",
            "0.8862895121879492\n",
            "0.5326237524664265\n",
            "0.8658441054253962\n",
            "0.7465582412858817\n",
            "0.8764963218252316\n",
            "0.8682316673809644\n",
            "0.914142313713413\n",
            "0.5138589761146378\n",
            "0.7838000655402724\n",
            "0.8071467134459452\n",
            "0.7957150668751548\n",
            "0.7811556507039221\n",
            "0.8398690636440699\n",
            "0.8377098942320547\n",
            "0.8960831634592834\n",
            "0.8293109146842489\n",
            "0.6618252585940767\n",
            "0.602593285757422\n",
            "0.7761141877503199\n",
            "0.8373655543839724\n",
            "0.821252024624438\n",
            "0.789574596306847\n",
            "0.8313198727055069\n",
            "0.7990798388708751\n",
            "0.7123842435236832\n",
            "0.8592310132982628\n",
            "0.6912911460861505\n",
            "0.6870698175174704\n",
            "0.8320489566275651\n",
            "0.7938164258109834\n",
            "0.8586858007273773\n",
            "0.717977724021633\n",
            "0.8927496307204699\n",
            "0.8625967701774439\n",
            "0.7961505900669251\n",
            "0.7802452429016505\n",
            "0.9314134491221163\n",
            "0.6959966541021715\n",
            "0.8121574132957391\n",
            "0.7755762730011522\n",
            "0.7941243265629064\n",
            "0.8830738058599288\n",
            "0.8564217263467208\n",
            "0.8322350190872885\n",
            "0.7761035209469896\n",
            "0.8054444258101217\n",
            "0.6310252000880017\n",
            "0.6822102967139896\n",
            "0.49493356921137255\n",
            "0.7471539926621553\n",
            "0.7885442903666585\n",
            "0.8482779266743694\n",
            "0.8667291735158015\n",
            "0.9010565120735919\n",
            "0.8404138431176206\n",
            "0.7699246424669427\n",
            "0.9150511133883505\n",
            "0.8541301997044362\n",
            "0.7834294619616045\n",
            "0.7922309368400203\n",
            "0.9219647943095928\n",
            "0.8159125525081986\n",
            "0.8761905002119601\n",
            "0.8065136418941041\n",
            "0.821987133712604\n",
            "0.8030909699850779\n",
            "0.8825169019211452\n",
            "0.9041961296436022\n",
            "0.7482274757411705\n",
            "0.6822504238673922\n",
            "0.577543929202742\n",
            "0.5633890792846439\n",
            "0.6305711442239469\n",
            "0.3855194196644377\n",
            "0.5723064606384376\n",
            "0.688842656276212\n",
            "0.6864328984859579\n",
            "0.8471943332291068\n",
            "0.33579438420547064\n",
            "0.7265708198325815\n",
            "0.7705011851475504\n",
            "0.6655234734392437\n",
            "0.50938684846275\n",
            "0.9132305440504063\n",
            "0.8220231723991551\n",
            "0.8739744611085316\n",
            "0.7312759154019923\n",
            "0.8839443846780803\n",
            "0.8944252908235776\n",
            "0.6085419403173983\n",
            "0.8192232914786898\n",
            "0.8751854848793402\n",
            "0.9146335871365485\n",
            "0.8385654529513454\n",
            "0.6701016737621661\n",
            "0.7121057098066994\n",
            "0.8554810721523037\n",
            "0.7746796692007802\n",
            "0.8526216503185159\n",
            "0.5972403621375054\n",
            "0.740557799006864\n",
            "0.7552487188158825\n",
            "0.7572695000372808\n",
            "0.6945152981021661\n",
            "0.8513664710135178\n",
            "0.8939900391720864\n",
            "0.8121818411774591\n",
            "0.68603773723255\n",
            "0.5733209109986996\n",
            "0.9145830785885632\n",
            "0.7860917374471323\n",
            "0.8175237168598724\n",
            "0.7819047021232675\n",
            "0.7317488769867952\n",
            "0.7621541307349694\n",
            "0.7823543815906896\n",
            "0.7406324815973391\n",
            "0.8642665253560349\n",
            "0.7947474247879462\n",
            "0.752744508092488\n",
            "0.6350804291551956\n",
            "0.7539199380614027\n",
            "0.7969980204183483\n",
            "0.8084400518797817\n",
            "0.8854802617981642\n",
            "0.8584098576762197\n",
            "0.7003182759671396\n",
            "0.8526351769729088\n",
            "0.7641820990699016\n",
            "0.9343860403247207\n",
            "0.5216594517461546\n",
            "0.9246131252544139\n",
            "0.6022365057045361\n",
            "0.9211493260132977\n",
            "0.8370455720792475\n",
            "0.8664358557684809\n",
            "0.8018951623345453\n",
            "0.866538081809248\n",
            "0.5724786107921497\n",
            "0.9123787425842086\n",
            "0.7584454413665744\n",
            "0.5249800608236804\n",
            "0.7554966478034287\n",
            "0.6332567222988167\n",
            "0.7813369053989986\n",
            "0.7897600535872877\n",
            "0.7186142459001943\n",
            "0.4531374128466679\n",
            "0.8466479819770458\n",
            "0.4242520419635463\n",
            "0.7451203783398128\n",
            "0.887118853928791\n",
            "0.8365798905751313\n",
            "0.8438383872842835\n",
            "0.8825480039736044\n",
            "0.8305379407387316\n",
            "0.6523655815354692\n",
            "0.9396868530164908\n",
            "0.8976317686979058\n",
            "0.6440077657563094\n",
            "0.890005628345062\n",
            "0.8447064257647665\n",
            "0.7129537012459342\n",
            "0.7641499274136254\n",
            "0.9294477933499797\n",
            "0.6152730113992663\n",
            "0.9330644900689801\n",
            "0.8206567066254679\n",
            "0.8477908392086513\n",
            "0.7137834065991693\n",
            "0.8572180547983316\n",
            "0.6253045243131362\n",
            "0.9100497072221106\n",
            "0.5685152216394374\n",
            "0.6403500385355292\n",
            "0.578722717637892\n",
            "0.6929492425938727\n",
            "0.7579904318837086\n",
            "0.8687222165062971\n",
            "0.7475287379961112\n",
            "0.9114088182511058\n",
            "0.7623866185066921\n",
            "0.8877302923366531\n",
            "0.8644962974332684\n",
            "0.5055632247634739\n",
            "0.7634177883575458\n",
            "0.8804442042582022\n",
            "0.8584835788579956\n",
            "0.7774844994128051\n",
            "0.8957104034326873\n",
            "0.870475747764183\n",
            "0.6908401164157237\n",
            "0.6354884860460089\n",
            "0.8169378988624099\n",
            "0.6080347093931341\n",
            "0.6625824905425054\n",
            "0.7476221587576486\n",
            "0.5838946949929333\n",
            "0.5185343731991792\n",
            "0.9009548743311364\n",
            "0.5731374005025542\n",
            "0.7652478351013319\n",
            "0.7530516714013684\n",
            "0.8175890097486509\n",
            "0.812870475891876\n",
            "0.6198114271115661\n",
            "0.8105330913672953\n",
            "0.627027943221081\n",
            "0.8388721302519965\n",
            "0.7514267024174411\n",
            "0.7373340542461225\n",
            "0.42590327092884045\n",
            "0.8003559431933739\n",
            "0.7685299196407854\n",
            "0.5954889810014622\n",
            "0.817024818367148\n",
            "0.7729103919331565\n",
            "0.8501088792202837\n",
            "0.7726422132962535\n",
            "0.7093348068469036\n",
            "0.677859276801988\n",
            "0.935069314369313\n",
            "0.6363852858946083\n",
            "0.7043610090319443\n",
            "0.7685952178707924\n",
            "0.8746162359965036\n",
            "0.6288129071518017\n",
            "0.7245351457697108\n",
            "0.7633229340160272\n",
            "0.18748236980184604\n",
            "0.6874560956990566\n",
            "0.8651826640922966\n",
            "0.8576383166555538\n",
            "0.8901597691851323\n",
            "0.7702559926755401\n",
            "0.8971681697670768\n",
            "0.6936887454519822\n",
            "0.6865728339258167\n",
            "0.822709550504287\n",
            "0.8198915259725366\n",
            "0.9073935234208491\n",
            "0.8499406400274342\n",
            "0.7981820701927007\n",
            "0.7554507675881049\n",
            "0.8101579510994981\n",
            "0.7020527472911866\n",
            "0.6879465054594432\n",
            "0.7856639666661857\n",
            "0.6549825734666694\n",
            "0.5673617467280696\n",
            "0.8349476559768239\n",
            "0.8137091037825506\n",
            "0.8580048430916968\n",
            "0.8611432256626462\n",
            "0.44053343595983513\n",
            "0.8920451232358704\n",
            "0.8421656718612746\n",
            "0.8561553561371235\n",
            "0.8151103194515409\n",
            "0.7589594713747541\n",
            "0.8243128077084296\n",
            "0.643461215936429\n",
            "0.5242368829471348\n",
            "0.940662048341163\n",
            "0.6656774322674811\n",
            "0.7544272321628933\n",
            "0.7311504269591215\n",
            "0.8395644175179939\n",
            "0.746620757309841\n",
            "0.838587826701979\n",
            "0.7354424191048241\n",
            "0.8822098184667473\n",
            "0.8031365941472981\n",
            "0.544208923132405\n",
            "0.7557498758059992\n",
            "0.89233299100024\n",
            "0.8011921430495361\n",
            "0.7314650755220398\n",
            "0.6269722008737684\n",
            "0.8782393955256643\n",
            "0.6663691433503325\n",
            "0.7791174865652887\n",
            "0.7815387692672658\n",
            "0.7743468812875833\n",
            "0.8207257239337122\n",
            "0.6024341031389814\n",
            "0.7470733126880775\n",
            "0.43035078729628234\n",
            "0.808012714899614\n",
            "0.7148744902607901\n",
            "0.8786684469465154\n",
            "0.7194844015921733\n",
            "0.8139456836867718\n",
            "0.668837688043709\n",
            "0.6555447717602442\n",
            "0.7164586430845739\n",
            "0.48286547776645106\n",
            "0.7708052191519835\n",
            "0.8749623651909918\n",
            "0.9234224895039692\n",
            "0.7449174749481227\n",
            "0.3360236777119785\n",
            "0.8392720486322938\n",
            "0.8035705311549404\n",
            "0.7471867300914585\n",
            "0.5200879280399678\n",
            "0.816924238910218\n",
            "0.6107105882540179\n",
            "0.632186896192093\n",
            "0.8915047818355838\n",
            "0.8963078111145205\n",
            "0.7223114997412521\n",
            "0.7241297716453868\n",
            "0.7717561577048633\n",
            "0.5135190591365657\n",
            "0.2577625422107696\n",
            "0.8020548237265815\n",
            "0.732557014308624\n",
            "0.39777249502702894\n",
            "0.5094316616891348\n",
            "0.37538656203803794\n",
            "0.8295539639538555\n",
            "0.9349327643689114\n",
            "0.921284736597577\n",
            "0.9183018628705266\n",
            "0.7605982880536811\n",
            "0.8163112692645722\n",
            "0.9437939470829692\n",
            "0.7563961063684975\n",
            "0.8697239801305037\n",
            "0.8044587661698431\n",
            "0.7728289424118445\n",
            "0.8666721023780063\n",
            "0.7256397635649551\n",
            "0.8598095439099415\n",
            "0.7406591586934058\n",
            "0.5155387153157194\n",
            "0.6574187670875757\n",
            "0.8264759486444324\n",
            "0.6833809977558039\n",
            "0.7283292321819973\n",
            "0.7784731334384126\n",
            "0.8054573966970454\n",
            "0.7637721805619794\n",
            "0.7489501124911926\n",
            "0.859454058896599\n",
            "0.8196051756220615\n",
            "0.8139675743659746\n",
            "0.9038917059715796\n",
            "0.8243202417313101\n",
            "0.6813198375236269\n",
            "0.8268748274592186\n",
            "0.8762615647417398\n",
            "0.8221128143653201\n",
            "0.7295906150999214\n",
            "0.8508045058056206\n",
            "0.6173606186824179\n",
            "0.73253055562398\n",
            "0.7496862543537757\n",
            "0.8139217379969574\n",
            "0.8427149983603517\n",
            "0.6825682112903816\n",
            "0.8770876240532082\n",
            "0.7521524892515519\n",
            "0.9043808861802819\n",
            "0.6800951034189052\n",
            "0.698664267928596\n",
            "0.5896166531645337\n",
            "0.8523578589384726\n",
            "0.8119014887207087\n",
            "0.5300284405505532\n",
            "0.7641529732767903\n",
            "0.8688956118345434\n",
            "0.921520501862328\n",
            "0.8666037936991329\n",
            "0.8372317516005277\n",
            "0.8996545691789067\n",
            "0.9308345471986084\n",
            "0.6447678847558693\n",
            "0.8708615556262324\n",
            "0.8346559923360674\n",
            "0.8258685023397231\n",
            "0.7294234857877189\n",
            "0.7578064303401705\n",
            "0.8609336212940806\n",
            "0.9322249897422527\n",
            "0.6594015692087836\n",
            "0.5128592031864367\n",
            "0.7927607505605755\n",
            "0.7618245367380843\n",
            "0.7257521326099443\n",
            "0.9229762005414847\n",
            "0.7964244178904071\n",
            "0.9195755419467906\n",
            "0.8310405265131994\n",
            "0.7445568446634714\n",
            "0.9393858143920626\n",
            "0.6960158466399199\n",
            "0.8459230495440532\n",
            "0.6882611927225998\n",
            "0.8775659371846031\n",
            "0.8229670832085594\n",
            "0.9034587567517665\n",
            "0.7896872072738427\n",
            "0.9265422991098344\n",
            "0.8217643509009875\n",
            "0.9000207125952825\n",
            "0.8537160502176679\n",
            "0.8005228034749203\n",
            "0.6106897200618546\n",
            "0.8729232082208713\n",
            "0.5311450200036153\n",
            "0.7074455913249973\n",
            "0.8340394137642501\n",
            "0.8560314640259864\n",
            "0.7881346350808018\n",
            "0.895714917224927\n",
            "0.6913990082873251\n",
            "0.6902716988895737\n",
            "0.3280440749110951\n",
            "0.664744800912034\n",
            "0.7288849277258961\n",
            "0.7553875492334385\n",
            "0.6506802728450902\n",
            "0.7208176598849094\n",
            "0.8087810818318704\n",
            "0.5877737093209056\n",
            "0.868163707765413\n",
            "0.857060185270261\n",
            "0.7275510383614618\n",
            "0.6899828460205351\n",
            "0.7998982340141945\n",
            "0.5164519144927684\n",
            "0.8420870205156236\n",
            "0.7168558734041972\n",
            "0.442252559448397\n",
            "0.6989719681684862\n",
            "0.8417957435409135\n",
            "0.8383314854127827\n",
            "0.8613338846852925\n",
            "0.9028615042640652\n",
            "0.801674308825411\n",
            "0.9042051079365521\n",
            "0.749545738787323\n",
            "0.7357881376026226\n",
            "0.6810030956659613\n",
            "0.8732923623980005\n",
            "0.8192897786176063\n",
            "0.7805011970916199\n",
            "0.8725225046472392\n",
            "0.6505927475618429\n",
            "0.6838207227356419\n",
            "0.8256165360758941\n",
            "0.7341692433579202\n",
            "0.8291312598648831\n",
            "0.8329279074166472\n",
            "0.7639503223010875\n",
            "0.7248033125128973\n",
            "0.36035817856538654\n",
            "0.5257241720246124\n",
            "0.8888182002042794\n",
            "0.8967031603798822\n",
            "0.8747186078413894\n",
            "0.8663603482165947\n",
            "0.6450570599910352\n",
            "0.918170839961346\n",
            "0.6136283487136389\n",
            "0.8514497973953101\n",
            "0.8499199753818557\n",
            "0.8997342192173549\n",
            "0.91239305436691\n",
            "0.6967022113809612\n",
            "0.8568589571551883\n",
            "0.9404157829916382\n",
            "0.637102583047068\n",
            "0.8199252711338955\n",
            "0.6666700779671724\n",
            "0.8043850945693937\n",
            "0.7794166664531983\n",
            "0.8375561226784443\n",
            "0.8337920469471185\n",
            "0.6642127276304325\n",
            "0.8904250590246962\n",
            "0.8586542732470195\n",
            "0.8033936607369446\n",
            "0.7119740741477109\n",
            "0.7827239926956489\n",
            "0.7943232113212504\n",
            "0.7948221344391145\n",
            "0.6405404629725605\n",
            "0.6096581526509158\n",
            "0.7103944284485288\n",
            "0.7385063263625594\n",
            "0.7823096311836972\n",
            "0.877311497722043\n",
            "0.8096799006646299\n",
            "0.8813867037092876\n",
            "0.7586520953719301\n",
            "0.7628284504837808\n",
            "0.673397897632128\n",
            "0.7925176007326631\n",
            "0.6726727929398724\n",
            "0.8571108496094585\n",
            "0.49985283742947023\n",
            "0.8017137126975041\n",
            "0.8616216183152128\n",
            "0.3638538875090432\n",
            "0.723466085846702\n",
            "0.6126078117896988\n",
            "0.8093607497233882\n",
            "0.7623565636890449\n",
            "0.9057307704998052\n",
            "0.7472000584945206\n",
            "0.3710386400889384\n",
            "0.9224367028974334\n",
            "0.7486633544566644\n",
            "0.8238903761511736\n",
            "0.8808001550443781\n",
            "0.8960540491532877\n",
            "0.686661479302232\n",
            "0.4613617001287003\n",
            "0.9043962179640698\n",
            "0.8569693572847299\n",
            "0.41798598988361957\n",
            "0.7010778721780767\n",
            "0.8878630577990146\n",
            "0.940937700062368\n",
            "0.8370221120352769\n",
            "0.7741262929573448\n",
            "0.48030946363412774\n",
            "0.6559626632755166\n",
            "0.9045677828173699\n",
            "0.866237526775004\n",
            "0.706987891720546\n",
            "0.7254811875505673\n",
            "0.5129755483307002\n",
            "0.8709955157116104\n",
            "0.7254031061747027\n",
            "0.7386570234786213\n",
            "0.91086583632283\n",
            "0.594872168385114\n",
            "0.7146581566596895\n",
            "0.8383900844307778\n",
            "0.3926549966767085\n",
            "0.8893064103825029\n",
            "0.8573992773951332\n",
            "0.8650628723034994\n",
            "0.8877050132625123\n",
            "0.7487080403150793\n",
            "0.7101373938876804\n",
            "0.8358933422540406\n",
            "0.8438010665720488\n",
            "0.8972432547071412\n",
            "0.49906507317063475\n",
            "0.7685299196407854\n",
            "0.5437153244108186\n",
            "0.6147334251157799\n",
            "0.6574264188705259\n",
            "0.7632500702050855\n",
            "0.7937436374739921\n",
            "0.4763455563048063\n",
            "0.8713615316194548\n",
            "0.8697851800853886\n",
            "0.7776672330783422\n",
            "0.8302421611882363\n",
            "0.7766849398432114\n",
            "0.6441285108514418\n",
            "0.7003336519579998\n",
            "0.72336200516271\n",
            "0.7821614140689866\n",
            "0.7068669443244397\n",
            "0.7981068154104553\n",
            "0.7786947927674372\n",
            "0.7916286852742721\n",
            "0.7899946546132576\n",
            "0.9357508931666088\n",
            "0.8481822209704302\n",
            "0.6967191223181451\n",
            "0.8491908503016791\n",
            "0.8394674393033276\n",
            "0.6575481965119404\n",
            "0.8002342170746404\n",
            "0.7466079067157108\n",
            "0.6264005194450671\n",
            "0.8344804158571433\n",
            "0.5482503396862117\n",
            "0.8470596918698704\n",
            "0.793088157435935\n",
            "0.8704759756561643\n",
            "0.9439418941593127\n",
            "0.8202813267247577\n",
            "0.8629727300259125\n",
            "0.6486256057002749\n",
            "0.7743459100903871\n",
            "0.5391237502313307\n",
            "0.8146249602881382\n",
            "0.5155906140828925\n",
            "0.734737712959901\n",
            "0.9023413666309626\n",
            "0.8689935936507505\n",
            "0.7945013287151307\n",
            "0.7184707123843117\n",
            "0.8634325041476436\n",
            "0.7973365883277328\n",
            "0.8636756453527527\n",
            "0.8917516378347208\n",
            "0.7638334433550997\n",
            "0.917678255444161\n",
            "0.7682013873953432\n",
            "0.7435944605436781\n",
            "0.9046543524865838\n",
            "0.937986234309434\n",
            "0.5916929363737482\n",
            "0.8184148976033354\n",
            "0.7325472459765533\n",
            "0.44618368965846483\n",
            "0.8313657125582684\n",
            "0.7894363781296476\n",
            "0.7760090099272161\n",
            "0.6462746088867773\n",
            "0.72941187953074\n",
            "0.8276594626032386\n",
            "0.8722644140021416\n",
            "0.29612013246638624\n",
            "0.5598983393176657\n",
            "0.8289436363287894\n",
            "0.8453421869751347\n",
            "0.848440884279189\n",
            "0.8326385633752713\n",
            "0.7489368435694678\n",
            "0.2980736923516957\n",
            "0.8908729451007995\n",
            "0.524145410810887\n",
            "0.6127329476671581\n",
            "0.8105888660024191\n",
            "0.8779426628338729\n",
            "0.8536686844558795\n",
            "0.4797905913108543\n",
            "0.8067356558494164\n",
            "0.6803342690967555\n",
            "0.8968912159170502\n",
            "0.8776627307204209\n",
            "0.8770464862897133\n",
            "0.8250818517726666\n",
            "0.8812582044091967\n",
            "0.8291571171451978\n",
            "0.8478588481223388\n",
            "0.6511249102743191\n",
            "0.6504211416875044\n",
            "0.8409291077922048\n",
            "0.7038249016089744\n",
            "0.7848308005126484\n",
            "0.4310874769559064\n",
            "0.6609529399043194\n",
            "0.8371756486782334\n",
            "0.8916728365169927\n",
            "0.9027339094746436\n",
            "0.8203410829213009\n",
            "0.6633516820195768\n",
            "0.7653048673285175\n",
            "0.7459409653148957\n",
            "0.9117796717846933\n",
            "0.6778793417519076\n",
            "0.7581774348152561\n",
            "0.8507172420351153\n",
            "0.7394257828529678\n",
            "0.6785536586173996\n",
            "0.7794104616645519\n",
            "0.8019742393224891\n",
            "0.7037890198351529\n",
            "0.7903024734939399\n",
            "0.7443955012660317\n",
            "0.8505864485245926\n",
            "0.9069796573208462\n",
            "0.7842028496522976\n",
            "0.7218929894781778\n",
            "0.7328219792698264\n",
            "0.8043049440217496\n",
            "0.6010344981526198\n",
            "0.6734362557929714\n",
            "0.804538911941646\n",
            "0.7438739863101748\n",
            "0.9157464925639403\n",
            "0.9206752237327764\n",
            "0.8097678088357992\n",
            "0.8414947870098556\n",
            "0.8069415377875729\n",
            "0.7765414352658347\n",
            "0.81760571108562\n",
            "0.8114843293087285\n",
            "0.7862025001726677\n",
            "0.821763183018348\n",
            "0.6947038576116092\n",
            "0.8415361630022719\n",
            "0.6861912971525099\n",
            "0.899663008595681\n",
            "0.8116496566814239\n",
            "0.6374008032315247\n",
            "0.492777702491466\n",
            "0.4354792882254193\n",
            "0.6320264892238849\n",
            "0.8198619510183008\n",
            "0.9355787709931916\n",
            "0.7702295942550554\n",
            "0.9166724566728485\n",
            "0.6619498152692214\n",
            "0.5852074539117612\n",
            "0.5910564529845828\n",
            "0.6053583031972303\n",
            "0.8790080890529752\n",
            "0.7219995167486978\n",
            "0.7261919126036533\n",
            "0.920874710542695\n",
            "0.6161943142234146\n",
            "0.3842056459425204\n",
            "0.9193700815183818\n",
            "0.8571540407057794\n",
            "0.6707209916786098\n",
            "0.7913350928634559\n",
            "0.8119714145398498\n",
            "0.49196269182576985\n",
            "0.7601492752940822\n",
            "0.7885788853332337\n",
            "0.8065778402384693\n",
            "0.7785447222180335\n",
            "0.8275362182840803\n",
            "0.7442466142404783\n",
            "0.9207407666309729\n",
            "0.8107305115479132\n",
            "0.906972934227233\n",
            "0.8999454531473293\n",
            "0.47237323846148455\n",
            "0.9103745366321044\n",
            "0.8034513745509761\n",
            "0.5136250856692594\n",
            "0.8850683029886857\n",
            "0.787896195687199\n",
            "0.8874950900394779\n",
            "0.7920198101122468\n",
            "0.7353480775260417\n",
            "0.815552498362911\n",
            "0.7500799142540876\n",
            "0.6631233538270278\n",
            "0.4896406827673615\n",
            "0.5654589137800795\n",
            "0.6180407366113518\n",
            "0.7580352709269393\n",
            "0.8676929659917643\n",
            "0.8328010229395848\n",
            "0.9419254575639247\n",
            "0.7793738645248559\n",
            "0.8594357583304107\n",
            "0.8966145379904042\n",
            "0.5964189081679819\n",
            "0.7487610606491488\n",
            "0.9401607372192702\n",
            "0.8338639430251682\n",
            "0.8252217165145908\n",
            "0.8906588617816006\n",
            "0.8000561672980242\n",
            "0.8154459936943639\n",
            "0.6813815615017947\n",
            "0.9172824152674515\n",
            "0.49961473118324906\n",
            "0.9137411376007045\n",
            "0.5940217061639044\n",
            "0.844476967735973\n",
            "0.8609994482833093\n",
            "0.6697561336018935\n",
            "0.8193355193221054\n",
            "0.49171840148236345\n",
            "0.8889694533634424\n",
            "0.7537403010154169\n",
            "0.8416090965104597\n",
            "0.7494595414491375\n",
            "0.7264509865887092\n",
            "0.7138713450667525\n",
            "0.885798209403986\n",
            "0.6748452313339833\n",
            "0.6256360859695399\n",
            "0.9170844065660917\n",
            "0.7404736471524086\n",
            "0.7041025432275839\n",
            "0.8808053293183916\n",
            "0.888384978827048\n",
            "0.852913745448584\n",
            "0.8109348479614518\n",
            "0.5334372561693975\n",
            "0.7156337416650693\n",
            "0.6021401666513608\n",
            "0.681889533854529\n",
            "0.8109189640951157\n",
            "0.7963576469572863\n",
            "0.5244184736168794\n",
            "0.6785424142948472\n",
            "0.7889925317915126\n",
            "0.8769649451350126\n",
            "0.7779513384673883\n",
            "0.6922672982042158\n",
            "0.6811248843157307\n",
            "0.8984844241948714\n",
            "0.8885188935218608\n",
            "0.6642157334525295\n",
            "0.7484844224375521\n",
            "0.8263550665993853\n",
            "0.792249064279153\n",
            "0.9065998859724178\n",
            "0.7720911878015145\n",
            "0.5903264352573815\n",
            "0.7892448025779677\n",
            "0.8636231463500834\n",
            "0.9338745272711148\n",
            "0.7514743696176035\n",
            "0.675658368641852\n",
            "0.7802657077235342\n",
            "0.9091471187346918\n",
            "0.8415746106425087\n",
            "0.7793786133712557\n",
            "0.823448181313593\n",
            "0.5095674136399199\n",
            "0.7504301575518632\n",
            "0.810556173210998\n",
            "0.6403162469748122\n",
            "0.774599307944751\n",
            "0.789272518330309\n",
            "0.7319084536049081\n",
            "0.6852447997101339\n",
            "0.49224701898584855\n",
            "0.9157120848734867\n",
            "0.7299661222249818\n",
            "0.6996844522504978\n",
            "0.7681325759484994\n",
            "0.6420410737602968\n",
            "0.5729246556998556\n",
            "0.7785789899110878\n",
            "0.8831721534903997\n",
            "0.8572842712353853\n",
            "0.7504626829805725\n",
            "0.6817207049318353\n",
            "0.8322943104690842\n",
            "0.7570161085309947\n",
            "0.9307478868808662\n",
            "0.8758853428485214\n",
            "0.8317780363911504\n",
            "0.6805189794498865\n",
            "0.66869734867007\n",
            "0.8877502509115419\n",
            "0.7160873667468011\n",
            "0.5305360491895195\n",
            "0.6452264494506621\n",
            "0.8330846354618505\n",
            "0.7646379959488351\n",
            "0.8618215633782472\n",
            "0.7442101315244892\n",
            "0.8392371174058098\n",
            "0.8653881759211607\n",
            "0.9403572937575855\n",
            "0.7077189500178166\n",
            "0.3129970119157946\n",
            "0.631108531423127\n",
            "0.8773653340612434\n",
            "0.740483586405973\n",
            "0.7797225369557594\n",
            "0.6580246982587004\n",
            "0.6393270388804834\n",
            "0.6640876626163479\n",
            "0.6845943805072441\n",
            "0.42060950642863376\n",
            "0.7875797456474461\n",
            "0.7861838698466649\n",
            "0.475370004316974\n",
            "0.6598975553863614\n",
            "0.7905053343154598\n",
            "0.799481404997348\n",
            "0.5648517727649176\n",
            "0.7109271778410267\n",
            "0.8294839219823318\n",
            "0.8213201121657281\n",
            "0.8294561864321296\n",
            "0.6542704649338229\n",
            "0.8660082549653805\n",
            "0.91672719061046\n",
            "0.710981315890093\n",
            "0.7835503703972759\n",
            "0.6833718998995499\n",
            "0.49057613990388294\n",
            "0.8002760604089244\n",
            "0.7303847326974771\n",
            "0.6854724421781403\n",
            "0.5531923342796348\n",
            "0.7090151861258225\n",
            "0.7230756768954982\n",
            "0.8695188369910173\n",
            "0.7909724331794094\n",
            "0.8802821435318258\n",
            "0.8455396608219476\n",
            "0.6335080072594239\n",
            "0.8831874536886246\n",
            "0.8611814193591563\n",
            "0.710288831068462\n",
            "0.8218593150384618\n",
            "0.8325779161715814\n",
            "0.8663271001954602\n",
            "0.8884204158502014\n",
            "0.4201057031619496\n",
            "0.6634880348161502\n",
            "0.8120374852006265\n",
            "0.8407464968186855\n",
            "0.8586931661256795\n",
            "0.5005688888639348\n",
            "0.6862847677307218\n",
            "0.6349995902968946\n",
            "0.5656409632041829\n",
            "0.9144288472787648\n",
            "0.7641778612893725\n",
            "0.9083942105507443\n",
            "0.6648403281786746\n",
            "0.8215498579090669\n",
            "0.926837314764366\n",
            "0.5225873912834764\n",
            "0.8029895117520375\n",
            "0.7718744763616705\n",
            "0.899539180173879\n",
            "0.8660086318097958\n"
          ]
        }
      ],
      "source": [
        "from rdkit.Chem import QED\n",
        "from rdkit import Chem\n",
        "\n",
        "for mol in lst:\n",
        "    m = Chem.MolFromSmiles(mol)\n",
        "    print(QED.default(m))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Q_lX5znQ_Z"
      },
      "source": [
        "Bonus 1 : Using rdkit, compute the quantitative estimation of drug-likeness (QED) of your generated molecules. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_mJSLmLFnQ_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jr0eRsEnQ_Z"
      },
      "source": [
        "Bonus 2 : try to adapt a transformer model training from hugging face to see if it is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DNHBtrMwnQ_Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}